{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Имхасина_3530202_л3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Имхасина, лаб3, генерация текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzPtBJYv3Bip",
        "outputId": "b4b8ae71-6164-44af-dc0b-75e5d2efcec8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b70Ze-1ahzls"
      },
      "source": [
        "\n",
        "используемый текст - пушкин евгений онегин"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "source": [
        "path_to_file = 'psh.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a49cdc0-8f90-40ea-8bc4-eb9f29b38375"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 185030 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50ae6f0-c6e1-4ac6-c008-3ad11b3ada14"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tHe мысля гордый свет забавить,\n",
            "\t\tВниманье дружбы возлюбя,\n",
            "\t\tХотел бы я тебе представить\n",
            "\t\tЗалог достойнее тебя,\n",
            "\t\tДостойнее души прекрасной,\n",
            "\t\tСвятой исполненной мечты,\n",
            "\t\tПоэзии живой и ясной,\n",
            "\t\tВысоких дум и простоты;\n",
            "\t\tНо так и быть – рукой прист\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0437702-8f42-4d85-ca65-aae3117acf16"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "148 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIvzNYNOmODS"
      },
      "source": [
        "необходимо отобразить строки в числовое представление. таблицы: одна отображает символы в числа, а другая - числа в символы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYyNlCNXymwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcae838-f208-4e93-9a52-2a3aef59b9ed"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\t':   0,\n",
            "  '\\n':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '(' :   4,\n",
            "  ')' :   5,\n",
            "  '*' :   6,\n",
            "  ',' :   7,\n",
            "  '-' :   8,\n",
            "  '.' :   9,\n",
            "  '/' :  10,\n",
            "  '0' :  11,\n",
            "  '1' :  12,\n",
            "  '2' :  13,\n",
            "  '3' :  14,\n",
            "  '4' :  15,\n",
            "  '5' :  16,\n",
            "  '6' :  17,\n",
            "  '7' :  18,\n",
            "  '8' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1VKcQHcymwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdb07a3-ac7a-4ddb-aab8-a2f054fcf811"
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\t\\tHe мысля го' ---- characters mapped to int ---- > [  0   0  33  57   2 120 135 125 119 139   2 111 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sizVmiImgtT"
      },
      "source": [
        "tf.data.Dataset.from_tensor_slices - чтобы преобразовать текстовый вектор в поток индексов символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UHJDA39zf-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9365fc8b-e792-475e-d4f4-dd17b59f0820"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\n",
            "\t\n",
            "H\n",
            "e\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4hkDU3i7ozi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9c02ca-3795-48c9-ddfd-6114ee78d84e"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\t\\tHe мысля гордый свет забавить,\\n\\t\\tВниманье дружбы возлюбя,\\n\\t\\tХотел бы я тебе представить\\n\\t\\tЗалог дос'\n",
            "'тойнее тебя,\\n\\t\\tДостойнее души прекрасной,\\n\\t\\tСвятой исполненной мечты,\\n\\t\\tПоэзии живой и ясной,\\n\\t\\tВысок'\n",
            "'их дум и простоты;\\n\\t\\tНо так и быть – рукой пристрастной\\n\\t\\tПрими собранье пестрых глав,\\n\\t\\tПолусмешных,'\n",
            "' полупечальных,\\n\\t\\tПростонародных, идеальных,\\n\\t\\tНебрежный плод моих забав,\\n\\t\\tБессонниц, легких вдохнов'\n",
            "'ений,\\n\\t\\tНезрелых и увядших лет,\\n\\t\\tУма холодных наблюдений\\n\\t\\tИ сердца горестных замет.\\n\\n\\n\\nГлава первая'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ba7685-2fb8-40ae-c0e7-9cb45a788a4e"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '\\t\\tHe мысля гордый свет забавить,\\n\\t\\tВниманье дружбы возлюбя,\\n\\t\\tХотел бы я тебе представить\\n\\t\\tЗалог до'\n",
            "Target data: '\\tHe мысля гордый свет забавить,\\n\\t\\tВниманье дружбы возлюбя,\\n\\t\\tХотел бы я тебе представить\\n\\t\\tЗалог дос'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eBu9WZG84i0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401e2881-0c19-42d0-89c3-685e1a856127"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 0 ('\\t')\n",
            "  expected output: 0 ('\\t')\n",
            "Step    1\n",
            "  input: 0 ('\\t')\n",
            "  expected output: 33 ('H')\n",
            "Step    2\n",
            "  input: 33 ('H')\n",
            "  expected output: 57 ('e')\n",
            "Step    3\n",
            "  input: 57 ('e')\n",
            "  expected output: 2 (' ')\n",
            "Step    4\n",
            "  input: 2 (' ')\n",
            "  expected output: 120 ('м')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training batches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q46eCoCmtW3"
      },
      "source": [
        "batch метод позволяет преобразовать  отдельные символы в последовательности желаемого размера."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa65b4d9-e38f-4baf-9940-ee3184df12d5"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRMPjIsshMgm"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J546Jy08k23K"
      },
      "source": [
        "tf.keras.layers.GRU : Тип RNN с размером units=rnn_units\n",
        "добавим еще слой гру"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "    #recurrent_initializer='orthogonal'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsrpOik5zhv"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Try the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9d63ef-e663-43d0-9ecf-33c1d68d1ecf"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 148) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8c0657-8a5f-4fc4-8a5c-1dee0f32bcd2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           37888     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 148)           151700    \n",
            "=================================================================\n",
            "Total params: 10,425,492\n",
            "Trainable params: 10,425,492\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w33nMdMJnQxH"
      },
      "source": [
        "Чтобы получить фактические прогнозы от модели,  необходимо выполнить выборку из выходного распределения, чтобы получить фактические индексы символов. Это распределение определяется логитами по словарю символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "Это дает нам предсказание каждого следующего символа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499c66be-6f18-4103-f355-fe5a8f4836ec"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([133,  88,  44,  95,  55,  68, 114,  45,  81,  64,  75, 146, 132,\n",
              "         6,   3,  46,  95,  47, 118,  45,  46,  76,  81,  68,  90,  76,\n",
              "        36,  24, 126,   4,  73,  46,  55,  70, 146,  65, 137,  17, 112,\n",
              "        54,  65,  83, 115,  80,  33,  59,  79,   7,  31,  24, 124,  31,\n",
              "        76,  70,  46,  83,  27, 121,  72,  52,  36,  46,  63,  73,  41,\n",
              "        23, 141, 101,  45,  13,  44, 130,  63,  98,   3,  86,  67, 113,\n",
              "        89,  91,  22,  83,  93, 134,  41,  67, 147, 134,  13,  28,  77,\n",
              "         3, 126, 129, 110,  89, 138, 145, 102, 115])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTbJMyA0jqQm"
      },
      "source": [
        "При необученной модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11630293-0df0-48ea-cb5b-067f1476ba88"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'входит в дом пустой,\\n\\t\\tГде жил недавно наш герой.\\n\\t\\tОна глядит: забытый в зале\\n\\t\\tКий на бильярде отд'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'щЗTПcpжVАlw…ш*!WПXкVWxАpКxL>т(uWcr…mэ6дbmВз»Hg«,F>рFxrWВBнt_LWkuQ<–ХV2TцkТ!ЕoеИЛ;ВНъQo€ъ2Cy!тхвИю„Цз'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd194751-2cf3-4450-e3a9-3736f94a294f"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 148)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.9969015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Чек-поинты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08006d47-dca0-4b71-a117-b7f6f48d74b2"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 3.9355\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 2.9423\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 2.5705\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 2.4154\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 2.3244\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 2.2584\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 2.1977\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 2.1394\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 2.0811\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 2.0163\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 1.9542\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 1.8876\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 1.8110\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 1.7292\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 1.6570\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 1.5678\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 4s 158ms/step - loss: 1.4779\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 1.3825\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 1.2845\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 1.1824\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 1.0692\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 5s 164ms/step - loss: 0.9570\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.8444\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.7363\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.6332\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5426\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.4671\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.4050\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.3552\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.3193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PGhJTesqAag"
      },
      "source": [
        "на 30ой итерации loss: 0.3193"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Генерация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIPcXllKjkdr"
      },
      "source": [
        "### Restore the latest checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2WJ2-XjkGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72fb7946-4c6f-4959-8715-06e2324e5700"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71xa6jnYVrAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4aa1341-2f19-49e0-e2f5-4e1f53b533d5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            37888     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 148)            151700    \n",
            "=================================================================\n",
            "Total params: 10,425,492\n",
            "Trainable params: 10,425,492\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 1000\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 1.0\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktovv0RFhrkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bbbb9c-d1a7-418c-c069-0859ba8297f1"
      },
      "source": [
        "print(generate_text(model, start_string=u\"А ты\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "А ты, милое!\n",
            "\t\tВысокой струею силится?\n",
            "\t\tОбминаденные моды,\n",
            "\t\tНо недоим к своим цветая, каковы, например: Агафон, Филат, Федора; Фекла и проч., употребляются. Голпава – жань пред собою\n",
            "\t\tОжи\n",
            "\t\tДа случай обычною руки\n",
            "\t\tНаснушал б она возолжал;\n",
            "\t\tВсегда как луна была согрета.\n",
            "\t\tПрощаясь перед натих одну и топор!\n",
            "\n",
            "\n",
            "\n",
            "XI. XIV\n",
            "\n",
            "\t\tНо здесь с подушки? ты ходет,\n",
            "\t\tСтеснялась каждочтою сладкой\n",
            "\t\tНе спится ей поне?\n",
            "\t\tЧто все подружки измарали\n",
            "\t\tС Оленька семейства оживляй,\n",
            "\t\tВ мой скользвинелай ла\n",
            "\t\tКак рано мог озаряя время расчислено пи вод,\n",
            "\t\tНо ясно бродит она внаманьем\n",
            "\t\tЗа глушилось.\n",
            "\t\tВ округом сего в очам.\n",
            "\t\tМанежь приятель, тишина,\n",
            "\t\tВ глуши лесов обедает двор\n",
            "\t\tИ отверил е. Ленский сам\n",
            "\t\tНе верит собственным глазам.\n",
            "\n",
            "\n",
            "\n",
            "XXI\n",
            "\n",
            "\t\tСнег пьердцым издалии злою\n",
            "\t\tВ Молюбому,\n",
            "\t\tИ верно б нос говорливой,\n",
            "\t\tИ ей открылся мир иной.\n",
            "\n",
            "\n",
            "\n",
            "XX\n",
            "\n",
            "\t\tRoosil пароем Тудски,\n",
            "\t\tРазвеселить веном уком,\n",
            "\tЕго Капридал,\n",
            "\t\tЧитая друзья! С тайне, стного сенья\n",
            "\t\tОбозык отчатность маг.\n",
            "\n",
            "\n",
            "* Сидит лиром следыми и пробка в пото\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}